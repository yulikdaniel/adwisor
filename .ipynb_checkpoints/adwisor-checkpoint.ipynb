{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "id": "6gICSGYpnJyI"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import spacy_transformers\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import os\n",
    "import re\n",
    "import xlsxwriter\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "id": "tDDcGUD6nJyV"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_trf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "id": "6LZrxF85nJyY"
   },
   "outputs": [],
   "source": [
    "def open_file(filename):\n",
    "    with open(filename, encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "id": "akthzbfhnJya"
   },
   "outputs": [],
   "source": [
    "def writeln(errors, filename):\n",
    "    workbook = xlsxwriter.Workbook(filename)\n",
    "    worksheet = workbook.add_worksheet()\n",
    "    #Fill in the column names\n",
    "    for x in range(len(errors[0])):\n",
    "        worksheet.write(0, x, errors[0][x])\n",
    "\n",
    "    col = 0\n",
    "    for row_num in range(1, len(errors)):\n",
    "        error = errors[row_num]\n",
    "        for x in range(len(error)):\n",
    "            worksheet.write(row_num, col + x, error[x])\n",
    "    workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "id": "kBOmgczUnJyc"
   },
   "outputs": [],
   "source": [
    "def find_subj(pred):\n",
    "    \n",
    "    # simple cases\n",
    "    subjects = []\n",
    "    subjects = [child for child in list(pred.children) if child.dep_.startswith(('nsubj', 'csubj'))]\n",
    "    \n",
    "    # if predicate is a conjunct or an auxiliary, we want to take subjects of its head\n",
    "    if pred.dep_ == 'conj' or pred.dep_.startswith('aux'):\n",
    "        subjects += [child for child in list(pred.head.children) if child.dep_.startswith(('nsubj', 'csubj'))]\n",
    "        \n",
    "    # handling 'there is' and 'there are' cases\n",
    "    if pred.lemma_ == 'be' and 'there' in list(i.text.lower() for i in pred.children):\n",
    "        subjects += [child for child in list(pred.children) if child.dep_ == 'attr']\n",
    "        \n",
    "    # handling conjuncts: multiple subjects as in 'Mother and father are key figures in a child's life'.\n",
    "    add_subj = []\n",
    "    for subject in subjects:\n",
    "        add_subj += list(subject.conjuncts)\n",
    "            \n",
    "    subjects += add_subj\n",
    "    \n",
    "    # the subjects' order may be different from sentence order, so we arrange it right\n",
    "    if subjects:\n",
    "        s = []\n",
    "        subj_i = sorted([subj.i for subj in subjects])\n",
    "        for i in subj_i:\n",
    "            s += [subject for subject in subjects if subject.i == i]\n",
    "            \n",
    "        subjects = s\n",
    "        \n",
    "    return subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "id": "x4mj0yyanJyg"
   },
   "outputs": [],
   "source": [
    "def find_pred_subj(doc):\n",
    "    pred_sub = list()\n",
    "    for token in doc:\n",
    "        if token.pos_ in ['AUX', 'VERB']:\n",
    "            # negation: cases like \"He doesn't scare me\"   \n",
    "            aux = None\n",
    "            if [ch for ch in list(token.lefts) if ch.dep_ == 'neg']:\n",
    "                children = list(token.children)\n",
    "                for ch in children:\n",
    "                    if ch.dep_ == 'aux' and not aux:\n",
    "                        aux = ch\n",
    "                if aux:\n",
    "                    pred_sub += [(aux, find_subj(aux))]\n",
    "                    \n",
    "                    \n",
    "            # if the predicate is analytical like 'I have done',\n",
    "            # spacy rightfully considers the participle to be the root,\n",
    "            # but we need grammatical info, so we will consider aux the root\n",
    "            if not aux: # for when negation is expressed with 'never' etc and does not need aux support\n",
    "                if token.tag_ in ['VBN', 'VBG']:\n",
    "                    aux = None\n",
    "                    children = list(token.children)\n",
    "                    for ch in children:\n",
    "                        if ch.dep_ == 'aux' and ch.pos_ in ['VERB', 'AUX'] and ch.tag_ != 'VBN':\n",
    "                            aux = ch\n",
    "                        elif not aux and ch.dep_ == 'auxpass' and ch.pos_ in ['VERB', 'AUX']:\n",
    "                            aux = ch\n",
    "                    if aux:\n",
    "                        pred_sub += [(aux, find_subj(aux))]\n",
    "\n",
    "                # all other cases\n",
    "                elif token.dep_ in ['ROOT', 'ccomp', 'xcomp', 'acl', 'relcl']:\n",
    "                    pred_sub += [(token, find_subj(token))]\n",
    "\n",
    "                # conjuncts: when there are multiple predicates connected by conjunction\n",
    "                elif token.dep_ == 'conj' and token.head.dep_ in ['ROOT', 'ccomp', 'xcomp', 'acl', 'relcl']:\n",
    "                    pred_sub += [(token, find_subj(token))]\n",
    "                \n",
    "    return pred_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "id": "OIP9NwitnJyl"
   },
   "outputs": [],
   "source": [
    "def errors(ps):\n",
    "    \n",
    "    res = []\n",
    "\n",
    "    for pair in ps:\n",
    "        subj_agr, pred_agr = None, None #what each must agree with, variables must coincide in the end\n",
    "        pred = pair[0]\n",
    "        subj = pair[1]\n",
    "#         print(pair)\n",
    "#         print([t.text for t in pred.children])\n",
    "#         for sub in subj:\n",
    "#             print([t.text for t in sub.lefts])\n",
    "        if len(subj) == 1:\n",
    "            subject = subj[0]\n",
    "            s = subject.text.lower()\n",
    "            subject_left_children = subject.lefts\n",
    "            subject_is_numeral = False\n",
    "            for child in subject_left_children:\n",
    "                if child.pos_ == 'NUM':\n",
    "                    subject_is_numeral = True\n",
    "                    break\n",
    "            if subject_is_numeral:\n",
    "                continue\n",
    "            if s not in ambiguous:\n",
    "                children = list(ch for ch in subject.children)\n",
    "                children_text = list(ch.text.lower() for ch in children)\n",
    "                \n",
    "                #singular only pronouns\n",
    "                if s in sing_only:\n",
    "                    subj_agr = 'sg'\n",
    "                    \n",
    "                # either singular or plural pronouns\n",
    "                # if they have an 'of N, N, N...', after them we will require check if verb agrees with the last noun\n",
    "                elif (s in {'some', 'any', 'none', 'all', 'most'} \\\n",
    "                      and 'of' in children_text):\n",
    "                    of = [ch for ch in children if ch.text.lower() == 'of'][0]\n",
    "                    noun = [ch for ch in of.children if ch.pos_ == 'NOUN']\n",
    "                    if noun:\n",
    "                        noun = noun[0]\n",
    "                        while [ch for ch in noun.children if (ch.dep_ == 'conj' and ch.pos_ == 'NOUN')]:\n",
    "                            noun = [ch for ch in noun.children if (ch.dep_ == 'conj' and ch.pos_ == 'NOUN')][-1]\n",
    "                        if noun.tag_ in ['NNS', 'NNPS'] or noun.text.lower() in plur_only:\n",
    "                            subj_agr = 'pl'\n",
    "                        elif noun.tag_ in ['NN', 'NNP'] or noun.text.lower() in sing_only:\n",
    "                            subj_agr = 'sg'\n",
    "                    \n",
    "                # plural only pronouns\n",
    "                elif s in plur_only and not children:\n",
    "                    subj_agr = 'pl'\n",
    "                    \n",
    "                elif s in {'i', 'we', 'you', 'they'}:\n",
    "                    subj_agr = 'pl'\n",
    "                elif s in {'he', 'she', 'it'}:\n",
    "                    subj_agr = 'sg'\n",
    "                    \n",
    "                elif s == 'number':\n",
    "                    if 'a' in children_text and 'of' in children_text:\n",
    "                        subj_agr = 'pl'\n",
    "                    else: subj_agr = 'sg'\n",
    "                    \n",
    "                # predicates in non-head clauses with 'who', 'that' agree with noun in head clause\n",
    "                elif s in ['who', 'that']:\n",
    "                    if pred.dep_ == 'relcl':\n",
    "                        #why relcl? we can only be sure about this tag that it is the case we're looking for.\n",
    "                        #other possible predicate tags include '...comp', but these also apply\n",
    "                        #in cases like \"I asked the boys who was the winner\",\n",
    "                        #which, although with incorrect word order,\n",
    "                        #are still clearly present in Russian essays\n",
    "                        #and will be parsed by spacy as 'ccomp'\n",
    "                        head = pred.head\n",
    "                        if not head.conjuncts:\n",
    "                            if head.tag_ in ['NNS', 'NNPS'] or head.text.lower() in plur_only:\n",
    "                                subj_agr = 'pl'\n",
    "                            elif head.tag_ in ['NN', 'NNP'] or head.text.lower() in sing_only:\n",
    "                                subj_agr = 'sg'\n",
    "                        else:\n",
    "                            conjuncts = list(head.conjuncts)+[head]\n",
    "                            for conjunct in conjuncts:\n",
    "                                if 'and' in list(child.text.lower() for child in conjunct.children):\n",
    "                                    subj_agr = 'pl'     \n",
    "                elif subject.tag_ in ['NNS', 'NNPS']:\n",
    "                    subj_agr = 'pl'\n",
    "                elif subject.tag_ in ['NN', 'NNP', 'VBG']:\n",
    "                    subj_agr = 'sg'\n",
    "                    \n",
    "        elif len(subj) > 1:\n",
    "            # 'Mother, father and brother were present.'\n",
    "            # If conjuncts are connected by 'and', he predicate is plural\n",
    "            # Exception: 'Every man, woman and child aprticipates in the tournament.'\n",
    "            if 'and' in list(child.text.lower() for child in list(list(subj[0].children)+list(subj[-2].children))):\n",
    "                left_subj_children = list(child.text.lower() for child in list(subj[0].lefts))\n",
    "                left_pred_children = list(child.text.lower() for child in list(pred.lefts))\n",
    "                is_uppercase = True\n",
    "                for sub in subj:\n",
    "                    if sub.tag_ != 'NNP':\n",
    "                        is_uppercase = False\n",
    "                        break\n",
    "                #Don't check: 'Jones and Sons is a respectable company.'\n",
    "                if is_uppercase:\n",
    "                    continue\n",
    "                # Don't check: 'There is Tom and Mary as a perfect example.'\n",
    "                if pred.text.lower() in ['is', 'are'] and 'there' in left_pred_children:\n",
    "                    continue\n",
    "                if 'every' in left_subj_children or 'each' in left_subj_children:\n",
    "                    subj_agr = 'sg'\n",
    "                else:\n",
    "                    subj_agr = 'pl'\n",
    "            # 'Mother, father or brother comes to pick up the kid.'\n",
    "            # If conjuncts are connected by 'or', verb agrees with the last one\n",
    "            elif any(a in list(child.text.lower() for child in list(list(subj[0].children)+list(subj[-2].children))) for a in ['or', 'nor']):\n",
    "                if subj[-1].tag_ in ['NNS', 'NNPS'] or subj[-1].text.lower() in plur_only:\n",
    "                    subj_agr = 'pl'\n",
    "                elif subj[-1].tag_ in ['NN', 'NNP', 'VBG'] or subj[-1].text.lower() in sing_only:\n",
    "                    subj_agr = 'sg'\n",
    "\n",
    "        if pred.tag_ == 'VBZ':\n",
    "            pred_agr = 'sg'\n",
    "        elif pred.tag_ == 'VBP':\n",
    "            pred_agr = 'pl'\n",
    "        elif pred.lemma == 'be':\n",
    "            if pred.text == 'was':\n",
    "                pred_agr = 'sg'\n",
    "            elif pred.text == 'were':\n",
    "                pred_agr = 'pl'\n",
    "\n",
    "        if subj_agr != pred_agr and subj_agr and pred_agr:\n",
    "            res += [pair]\n",
    "            \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "7YywB0bWnJyp"
   },
   "outputs": [],
   "source": [
    "def search(directory = 'test', only_errors=True): #If used with excel files, should be only used with similar format files, otherwise additional info can be messy\n",
    "    final = []\n",
    "    text_files = [os.path.join(dp, f) for dp, dn, filenames in os.walk(directory) for f in filenames if os.path.splitext(f)[1] == '.txt']\n",
    "    excel_files = [os.path.join(dp, f) for dp, dn, filenames in os.walk(directory) for f in filenames if os.path.splitext(f)[1] == '.xlsx']\n",
    "\n",
    "    if text_files: #If there is at least one txt file, we assume that the format is default\n",
    "        if only_errors:\n",
    "            final.append((\"Sentence\", \"Errors\", \"Filename\"))\n",
    "        else:\n",
    "            final.append((\"Sentence\", \"Errors\", \"Filename\", \"Has Error\"))\n",
    "\n",
    "    for file in text_files:\n",
    "        text = open_file(file)\n",
    "        sentences = sent_tokenize(text)\n",
    "        for sent in sentences:\n",
    "            sent = re.sub(r'<.*?>', '', sent)\n",
    "            sent = re.sub(r' +', ' ', sent)\n",
    "            doc = nlp(sent)\n",
    "            ps = find_pred_subj(doc)\n",
    "            # ps looks like [(predicate1, [subject1, subject2]), (predicate2, [subject1])]\n",
    "            er = errors(ps)\n",
    "#             er = [error for error in er if not subjunctive(sent, error[0])]\n",
    "            \n",
    "            if only_errors:\n",
    "                if er:\n",
    "                    final.append((sent,\n",
    "                                  \",\\n\".join([\"{} {}\".format(*er[x]) for x in range(len(er))]), # Wrong subjs and preds,\n",
    "                                 file))\n",
    "            else:\n",
    "                final.append((sent,\n",
    "                              \", \".join([\"({} {})\".format(*er[x]) for x in range(len(er))]),\n",
    "                              file,\n",
    "                              int(len(er) != 0)))  #Whether or not errors were found\n",
    "\n",
    "    for file in excel_files:\n",
    "        df = pandas.read_excel(file)\n",
    "        if not final:\n",
    "            additional_columns = tuple([x for x in df.columns if x != \"sentence\"])\n",
    "            if only_errors:\n",
    "                final.append((\"Sentence\", \"Errors\", \"Filename\") + additional_columns)\n",
    "            else:\n",
    "                final.append((\"Sentence\", \"Errors\", \"Filename\", \"Has Error\") + additional_columns)\n",
    "\n",
    "        for row_num in range(df.shape[0]):\n",
    "            sent = df[\"sentence\"].iat[row_num]\n",
    "            sent = re.sub(r'<.*?>', '', sent)\n",
    "            sent = re.sub(r' +', ' ', sent)\n",
    "            doc = nlp(sent)\n",
    "            ps = find_pred_subj(doc)\n",
    "            # ps looks like [(predicate1, [subject1, subject2]), (predicate2, [subject1])]\n",
    "            er = errors(ps)\n",
    "#             er = [error for error in er if not subjunctive(sent, error[0])]\n",
    "            \n",
    "            if only_errors:\n",
    "                if er:\n",
    "                    final.append((sent,\n",
    "                                  \",\\n\".join([\"{} {}\".format(*er[x]) for x in range(len(er))]), # Wrong subjs and preds,\n",
    "                                 file,\n",
    "                                 *[df[column].iat[row_num] for column in additional_columns]))\n",
    "            else:\n",
    "                final.append((sent,\n",
    "                              \", \".join([\"({} {})\".format(*er[x]) for x in range(len(er))]),\n",
    "                              file,\n",
    "                              int(len(er) != 0), #Whether or not errors were found\n",
    "                              *[df[column].iat[row_num] for column in additional_columns]))\n",
    "        \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "id": "7w64supcnJys"
   },
   "outputs": [],
   "source": [
    "def subjunctive(sent, pred):\n",
    "    adj_prt = {'advisable', 'best', 'crucial', 'desirable', 'vital',\n",
    "               'essential', 'imperative', 'important', 'moved',\n",
    "               'necessary', 'prohibited', 'unthinkable', 'urgent',\n",
    "               'required', 'stipulated', 'requested', 'recommended',\n",
    "               'advised', 'proposed', 'adamant', 'anxious', \n",
    "               'determined', 'eager', 'insistent', 'keen'}\n",
    "    \n",
    "    clause_is_subjunctive = False\n",
    "    that_list = []\n",
    "\n",
    "    if 'that' in sent.lower():\n",
    "        doc = nlp(sent)\n",
    "        that_list = [token for token in doc if token.text.lower() == 'that']\n",
    "        for that in that_list: \n",
    "            # VERB/NOUN + that + CONJUNCTIVE\n",
    "            if (that.head.i == pred.i \\\n",
    "                and pred.dep_ == 'ccomp' \\\n",
    "                and pred.head.pos_ in ['VERB', 'NOUN'] \\\n",
    "                and pred.head.lemma_ in {'advise', 'ask', 'command', 'demand', 'desire',\n",
    "                                         'insist', 'move', 'order', 'prefer', 'propose',\n",
    "                                         'recommend', 'request', 'stipulate', 'suggest', 'urge',\n",
    "                                         'motion', 'order', 'preference', 'proposal', 'recommendation',\n",
    "                                         'request', 'stipulation', 'suggestion'}):\n",
    "                clause_is_subjunctive = True\n",
    "\n",
    "            # SUBJECT + [be] ADJ/PRTC + that + CONJUNCTIVE\n",
    "            elif (that.head.i == pred.i and pred.dep_ == 'ccomp'):\n",
    "                if (pred.head.lemma_ == 'be' and \\\n",
    "                    any(a in adj_prt for a in list(b.text.lower() for b in pred.head.children))) \\\n",
    "                    or (pred.head.tag_ in ['VBN', 'JJ'] and \\\n",
    "                        pred.head.text in adj_prt):\n",
    "                        clause_is_subjunctive = True\n",
    "\n",
    "    return clause_is_subjunctive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e4QFskfGnJyv",
    "outputId": "f5745206-7a79-416f-d7af-3611417a9a5c"
   },
   "outputs": [],
   "source": [
    "ambiguous = {'bison', 'cod', 'deer', 'fish', 'moose', 'boar', 'salmon', 'sheep',\n",
    "            'shrimp', 'swine', 'trout', 'buffalo', 'grouse', 'elk', 'fruit', 'reindeer',\n",
    "            'offspring', 'pike',\n",
    "            'statistics', 'politics', 'mechanics', 'economics',            \n",
    "            'government', 'data', 'police', 'team', 'jury', 'family',\n",
    "            'half', 'class', 'majority', 'part', 'percent', '%', 'cent', 'lot'}\n",
    "\n",
    "sing_only = {'each', 'either', 'neither', 'one', 'nobody',\n",
    "            'nothing', 'anyone', 'anybody', 'anything', 'someone', \n",
    "            'somebody', 'something', 'everyone', 'everybody', 'everything', \n",
    "             'this', 'one', 'other', 'which'}\n",
    "\n",
    "plur_only = {'several', 'few', 'many', 'both', 'these', 'those'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "pEYYhZiFnJyx"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "f = search()\n",
    "fa = non_subjunctive(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 53s, sys: 152 ms, total: 2min 53s\n",
      "Wall time: 43.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "f = search('../razmetka/', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeln(f, \"itog.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(*args):\n",
    "    return search(os.path.join(*args), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(*args, write_errs=None, print_wrong=False): # Function to test the model on a directory with a correct.txt file and a wrong.txt file\n",
    "    outpus = run_model(*args)\n",
    "    \n",
    "    if write_errs is not None:\n",
    "        writeln(output, write_errs)\n",
    "    \n",
    "    false_pos = 0\n",
    "    true_pos = 0\n",
    "    false_neg = 0\n",
    "    true_neg = 0\n",
    "    for x in output:\n",
    "        if x[2] == os.path.join(*args, \"correct.txt\"):\n",
    "            if x[3] == 0:\n",
    "                true_neg += 1\n",
    "            else:\n",
    "                false_pos += 1\n",
    "        else:\n",
    "            if x[3] == 0:\n",
    "                false_neg += 1\n",
    "            else:\n",
    "                true_pos += 1\n",
    "\n",
    "    precision = (true_pos + true_neg) / (true_pos + true_neg + false_pos + false_neg)\n",
    "    recall = true_pos / (true_pos + false_neg)\n",
    "    print(\"Precision = {}\\nRecall = {}\\n\".format(round(precision, 2), round(recall, 2)))\n",
    "\n",
    "def evaluate(level, **kwargs): # level should be equal to \"easy\", \"medium\" or \"insane\"\n",
    "    print(level.capitalize(), \"tests:\")\n",
    "    test_model(\"test\", \"evaluate\", level, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Easy tests:\n",
      "Precision = 0.95\n",
      "Recall = 0.88\n",
      "\n",
      "CPU times: user 3.56 s, sys: 0 ns, total: 3.56 s\n",
      "Wall time: 896 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "evaluate(\"easy\", print_wrong=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'noun, proper singular'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"NNP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVUa4oOMnJyz"
   },
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0uoCviYynJy6",
    "outputId": "22c45de3-8918-4794-cbbf-e424fc63af56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mother and father are important figures in a child's life.\n",
      "[(are, [Mother, father])]\n",
      "0\tMother\t\t\tNOUN\tmother\t\tNN\t\tnsubj\t\t3\n",
      "1\tand\t\t\tCCONJ\tand\t\tCC\t\tcc\t\t0\n",
      "2\tfather\t\t\tNOUN\tfather\t\tNN\t\tconj\t\t0\n",
      "3\tare\t\t\tAUX\tbe\t\tVBP\t\tROOT\t\t3\n",
      "4\timportant\t\t\tADJ\timportant\t\tJJ\t\tamod\t\t5\n",
      "5\tfigures\t\t\tNOUN\tfigure\t\tNNS\t\tattr\t\t3\n",
      "6\tin\t\t\tADP\tin\t\tIN\t\tprep\t\t5\n",
      "7\ta\t\t\tDET\ta\t\tDT\t\tdet\t\t8\n",
      "8\tchild\t\t\tNOUN\tchild\t\tNN\t\tposs\t\t10\n",
      "9\t's\t\t\tPART\t's\t\tPOS\t\tcase\t\t8\n",
      "10\tlife\t\t\tNOUN\tlife\t\tNN\t\tpobj\t\t6\n",
      "11\t.\t\t\tPUNCT\t.\t\t.\t\tpunct\t\t3\n",
      "['_', '__bytes__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__pyx_vtable__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__unicode__', 'ancestors', 'check_flag', 'children', 'cluster', 'conjuncts', 'dep', 'dep_', 'doc', 'ent_id', 'ent_id_', 'ent_iob', 'ent_iob_', 'ent_kb_id', 'ent_kb_id_', 'ent_type', 'ent_type_', 'get_extension', 'has_dep', 'has_extension', 'has_head', 'has_morph', 'has_vector', 'head', 'i', 'idx', 'iob_strings', 'is_alpha', 'is_ancestor', 'is_ascii', 'is_bracket', 'is_currency', 'is_digit', 'is_left_punct', 'is_lower', 'is_oov', 'is_punct', 'is_quote', 'is_right_punct', 'is_sent_end', 'is_sent_start', 'is_space', 'is_stop', 'is_title', 'is_upper', 'lang', 'lang_', 'left_edge', 'lefts', 'lemma', 'lemma_', 'lex', 'lex_id', 'like_email', 'like_num', 'like_url', 'lower', 'lower_', 'morph', 'n_lefts', 'n_rights', 'nbor', 'norm', 'norm_', 'orth', 'orth_', 'pos', 'pos_', 'prefix', 'prefix_', 'prob', 'rank', 'remove_extension', 'right_edge', 'rights', 'sent', 'sent_start', 'sentiment', 'set_extension', 'set_morph', 'shape', 'shape_', 'similarity', 'subtree', 'suffix', 'suffix_', 'tag', 'tag_', 'tensor', 'text', 'text_with_ws', 'vector', 'vector_norm', 'vocab', 'whitespace_']\n",
      "Mother figures .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    }
   ],
   "source": [
    "s = [\"Mother and father are important figures in a child's life.\"]\n",
    "\n",
    "for ss in s:\n",
    "    doc = nlp(ss)\n",
    "    print(doc)\n",
    "    print(find_pred_subj(doc))\n",
    "    \n",
    "    \n",
    "for token in doc:\n",
    "    print(\"%s\\t%s\\t\\t\\t%s\\t%s\\t\\t%s\\t\\t%s\\t\\t%s\" % (token.i, token.text, token.pos_, token.lemma_, token.tag_, token.dep_, token.head.i))\n",
    "    \n",
    "print(dir(doc[0]))\n",
    "print(' '.join(list(ch.text for ch in doc[3].children)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "77-IWInUnJzE",
    "outputId": "dc39df0d-099f-4506-c8b0-f0f7e68525ea",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'object of preposition'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"pobj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "id": "BsXLrsQonJzH"
   },
   "outputs": [],
   "source": [
    "st = sent_tokenize(\"Apples is good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "adwisor.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
